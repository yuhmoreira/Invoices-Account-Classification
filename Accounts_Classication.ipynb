{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK resources for tokenization and stop words\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831bf87",
   "metadata": {},
   "source": [
    "### --- Exploratory Data Analysis (EDA) ---\n",
    "\n",
    "**Purpose:** Understand the dataset structure and identify patterns impacting classification.\n",
    "\n",
    "**Why:** Analyzing class distribution, numerical values, and text terms helps detect imbalances or discriminative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868002ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_inv = pd.read_excel(\n",
    "    '/kaggle/input/accounting-classification-suppliers-purchases/invoices_classification.xlsx',\n",
    "    engine='openpyxl'\n",
    ")\n",
    "\n",
    "# Display basic dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(df_inv.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first five rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df_inv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf19efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last five rows\n",
    "print(\"\\nLast 5 Rows:\")\n",
    "print(df_inv.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d545a4",
   "metadata": {},
   "source": [
    "> We can see that the dataset is already split into training and testing sets by the collumn 'Dataset'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a59cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Distribution of Account_Number\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=df_inv, x='Account_Number', order=df_inv['Account_Number'].value_counts().index)\n",
    "plt.title('Distribution of Classes (Account_Number)')\n",
    "plt.xlabel('Account Number')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d9f51",
   "metadata": {},
   "source": [
    "> There are many classes with few registers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contingency table\n",
    "contingency_table = pd.crosstab(df_inv['Supplier_Code'], df_inv['Account_Number'])\n",
    "\n",
    "# Calculate Cramér's V\n",
    "def cramers_v(contingency_table):\n",
    "    \"\"\"\n",
    "    Purpose: Compute Cramér's V to measure association between two categorical variables.\n",
    "    \"\"\"\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    n = contingency_table.sum().sum()\n",
    "    min_dim = min(contingency_table.shape) - 1\n",
    "    return np.sqrt(chi2 / (n * min_dim))\n",
    "\n",
    "cramers_v_value = cramers_v(contingency_table)\n",
    "print(f\"\\nCramér's V between {'Supplier_Code'} and Account_Number: {cramers_v_value:.3f}\")\n",
    "print(f\"Chi-square p-value: {chi2_contingency(contingency_table)[1]:.3f}\")\n",
    "# Why: Cramér's V (0 to 1) indicates association strength; a low p-value (<0.05) suggests a significant relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d90ba",
   "metadata": {},
   "source": [
    "> The **chi-square** test evaluates whether the relationship between Supplier_Code and Account_Number is statistically significant. The p-value indicates the probability that the observed association occurred by chance.\n",
    "> \n",
    "> \n",
    "> \n",
    "> **Cramér's V = 0.842** indicates that suppliers are a key differentiator for accounting accounts.\n",
    "> \n",
    "> \n",
    "> \n",
    "> A **p-value of 0.000** (typically < 0.05) means the relationship is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Heatmap of contingency table\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Contingency Table: Supplier_Code vs. Account_Number')\n",
    "plt.xlabel('Account Number')\n",
    "plt.ylabel('Supplier_Code')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031251de",
   "metadata": {},
   "source": [
    "> The heatmap allows us to visualize the distribution of supplier-account pairs, emphasizing patterns of strong association.\n",
    "> \n",
    "> \n",
    "> \n",
    "> We observe that most suppliers are linked to a single account, with only a few having items classified across multiple accounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5862cf",
   "metadata": {},
   "source": [
    "### --- Data Preprocessing ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4325c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets.\n",
    "\n",
    "df_inv_train = df_inv[df_inv[\"Dataset\"] == \"Training\"]\n",
    "df_inv_test = df_inv[df_inv[\"Dataset\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and handle missing values to prepare the dataset for modeling.\n",
    "\n",
    "X_train = df_inv_train[\"Supplier_Name\"].fillna(\"\") + \" \" + df_inv_train[\"Item_Description\"].fillna(\"\")\n",
    "y_train = df_inv_train[\"Account_Number\"]\n",
    "\n",
    "X_test = df_inv_test[\"Supplier_Name\"].fillna(\"\") + \" \" + df_inv_test[\"Item_Description\"].fillna(\"\")\n",
    "y_test = df_inv_test[\"Account_Number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a dictionary of three text vectorization methods \n",
    "# (TfidfVectorizer, CountVectorizer, and HashingVectorizer) and evaluates their performance\n",
    "\n",
    "vectorizers = {\n",
    "    \"TF-IDF\": TfidfVectorizer(ngram_range=(1,2)),\n",
    "    \"Count\": CountVectorizer(ngram_range=(1,2)),\n",
    "    \"Hashing\": HashingVectorizer(n_features=5000, alternate_sign=False)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, vec in vectorizers.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"vec\", vec),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring=\"f1_macro\")\n",
    "    results[name] = scores.mean()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fac849",
   "metadata": {},
   "source": [
    "Text vectorization converts textual data (e.g., \"Cleaning products (kit)\") into numerical features that a machine learning model like logistic regression can process. Different vectorizers capture different aspects of the text:\n",
    "\n",
    "**TfidfVectorizer:** Emphasizes rare but important terms by weighting them higher (Term Frequency-Inverse Document Frequency).\n",
    "\n",
    "**CountVectorizer:** Counts the frequency of words or n-grams, treating all terms equally.\n",
    "\n",
    "**HashingVectorizer:** Maps terms to a fixed-size feature space using a hash function, useful for large datasets but less interpretable.\n",
    "\n",
    "Choosing the right vectorizer is critical for model performance, especially since the dataset includes Item_Description with discriminative terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline for preprocessing and modeling.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"count\", CountVectorizer(ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43115702",
   "metadata": {},
   "source": [
    "> A pipeline automates data transformation (text and numerical) and model application, ensuring consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d562880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the model’s performance on the test set, providing metrics\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9a96c",
   "metadata": {},
   "source": [
    "**Accuracy** = 0.92 (92%): The model correctly classified 92% of the 51 test instances.\n",
    "\n",
    "**Macro Average** (Precision = 0.83, Recall = 0.86, F1 = 0.83): These metrics average performance across all classes equally, regardless of class frequency. The macro F1-score of 0.83 indicates good performance across classes.\n",
    "\n",
    "**Weighted Average** (Precision = 0.91, Recall = 0.92, F1 = 0.91): These metrics weight each class by its frequency in the test set. The higher weighted F1 (0.91 vs. 0.83 macro) suggests the model performs better on frequent classes but may struggle with rare ones.\n",
    "\n",
    "**Sample Size** = 51: The test set has 51 instances, which is relatively small, so performance metrics may be sensitive to a few misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with actual and predicted labels\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Count correct predictions per class\n",
    "accuracy_by_class = results_df.groupby('Actual').apply(\n",
    "    lambda x: (x['Actual'] == x['Predicted']).sum()\n",
    ").rename('Correct')\n",
    "\n",
    "# Count total samples per class\n",
    "total_by_class = results_df['Actual'].value_counts().rename('Total')\n",
    "\n",
    "# Combine the two\n",
    "accuracy_df = pd.concat([accuracy_by_class, total_by_class], axis=1)\n",
    "accuracy_df['Accuracy'] = accuracy_df['Correct'] / accuracy_df['Total']\n",
    "\n",
    "# Sort from lowest to highest accuracy\n",
    "accuracy_df = accuracy_df.sort_values(by='Accuracy')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=accuracy_df.index, y=accuracy_df['Accuracy'])\n",
    "plt.title('Accuracy by Account_Number)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter accounts with accuracy less than 1.0\n",
    "accounts_with_errors = accuracy_df[accuracy_df['Accuracy'] < 1.0].index\n",
    "\n",
    "# Filter df_inv for these accounts\n",
    "df_with_errors = df_inv[df_inv['Account_Number'].isin(accounts_with_errors)]\n",
    "\n",
    "# Display\n",
    "df_with_errors.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the rows with classification errors\n",
    "errors_df = results_df[results_df['Actual'] != results_df['Predicted']]\n",
    "\n",
    "# Display the errors\n",
    "print(errors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grup by Account_Number e calculates average Item_Value\n",
    "avg_value = df_inv.groupby('Account_Number')['Item_Value'].mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "avg_value.plot(kind='bar', color='skyblue')\n",
    "plt.title('Averege Value by Account Number')\n",
    "plt.ylabel('Averege Value (Item_Value)')\n",
    "plt.xlabel('Account Number')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ed6b1",
   "metadata": {},
   "source": [
    "> **Account 1001004:** This account exhibits a slightly higher average Item_Value compared to accounts 5000024 and 5000034. This difference likely stems from thresholds set by company policies or regulations for classifying an asset as a fixed asset (immobilized) versus a low-value expense. Including Item_Value as a feature could improve the model’s ability to correctly classify this account by capturing these value-based distinctions.\n",
    "> \n",
    "> \n",
    "> \n",
    "> **Account 5000060:** The model predicted account 4000060 instead of 5000060. The primary distinguishing information between accounts in group 4 (e.g., 4000060) and group 5 (e.g., 5000060) lies in the Item_Description field, specifically the presence of 'B' in \"Monthly rent – Warehouse B\" for group 5 versus 'A' in \"Monthly rent – Warehouse A\" for group 4. As the rental prices for Warehouse A and Warehouse B differ, incorporating Item_Value as a feature may enhance the model’s ability to differentiate these accounts, potentially improving accuracy.\n",
    "> \n",
    "> \n",
    "> \n",
    "> **Account 4000006:** The supplier CSF Wholesale and Retail and the item Cleaning products (kit) are associated with both accounts 4000006 and 4000013 due to a misclassification in the dataset. It will be necessary to assign the correct account to improve the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe596e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the Account_Number for invoice 793 to align with invoice 491.\n",
    "df_inv.loc[(df_inv['Invoice'] == 793) &\n",
    "           (df_inv['Supplier_Name'] == 'CSF Wholesale and Retail') &\n",
    "           (df_inv['Item_Description'] == 'Cleaning products (kit)'),\n",
    "           'Account_Number'] = '4000013'\n",
    "\n",
    "# Verify the correction\n",
    "print(\"\\nVerification of correction for invoice 793:\")\n",
    "print(df_inv[(df_inv['Invoice'] == 793) &\n",
    "             (df_inv['Supplier_Name'] == 'CSF Wholesale and Retail')]\n",
    "             [['Invoice', 'Supplier_Name', 'Item_Description', 'Account_Number']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix the supplier name with something like \"SUPPLIER_\", which helps the model learn that these are \n",
    "# tokens distinct from those in the description, while still keeping everything in the same text field\n",
    "df_inv['Input_Text'] = df_inv['Item_Description'] + ' SUPPLIER_' + df_inv['Supplier_Name']\n",
    "\n",
    "# Create Log_Item_Value\n",
    "df_inv['Log_Item_Value'] = np.log1p(df_inv['Item_Value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets.\n",
    "df_inv_train = df_inv[df_inv[\"Dataset\"] == \"Training\"]\n",
    "df_inv_test = df_inv[df_inv[\"Dataset\"] == \"Test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b966976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X_train = df_inv_train[['Input_Text', 'Item_Value', 'Log_Item_Value']]\n",
    "y_train = df_inv_train['Account_Number'].astype(str)  # Ensure string\n",
    "X_test = df_inv_test[['Input_Text', 'Item_Value', 'Log_Item_Value']]\n",
    "y_test = df_inv_test['Account_Number'].astype(str)\n",
    "\n",
    "# Define pipeline\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('text', CountVectorizer(ngram_range=(1, 2), max_features=3000,\n",
    "                             stop_words=['and', 'the', 'a', 'of', 'with', 'for', 'in', 'on', 'it', 'from', 'to']), 'Input_Text'),\n",
    "    ('value', StandardScaler(), ['Item_Value', 'Log_Item_Value'])\n",
    "])\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02dbf61",
   "metadata": {},
   "source": [
    "**Log_Item_Value** is created by applying a logarithmic transformation to Item_Value. Handles Skewed Distributions: Invoice amounts (Item_Value) are often right-skewed, with many small values and a few large outliers (e.g., 100 vs. 100000). The log transformation compresses the range, reducing the impact of extreme values and making the distribution more normal-like, which improves LogisticRegression’s performance.\n",
    "\n",
    "**StandardScaler** standardizes Item_Value and Log_Item_Value by subtracting the mean and dividing by the standard deviation, resulting in features with a mean of 0 and a standard deviation of 1. CountVectorizer produces sparse, non-negative integer counts (e.g., term frequencies from Input_Text), while Item_Value (e.g., 500, 100000) and Log_Item_Value (e.g., 6.2, 11.5) have different scales. StandardScaler ensures all features contribute equally to LogisticRegression’s optimization, preventing large Item_Value magnitudes from dominating the model.\n",
    "\n",
    "The **stop_words** are frequent but non-discriminative terms that appear across many invoices (e.g., “and” in “Cleaning products and supplies”). Excluding them focuses CountVectorizer on meaningful tokens (e.g., “Cleaning”, “SUPPLIER_CSF”), improving the signal-to-noise ratio and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and evaluate\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Test accuracy:\", pipeline.score(X_test, y_test))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b82f6",
   "metadata": {},
   "source": [
    "> The earlier pipeline (92% accuracy, macro F1 = 0.83) used only Input_Text with CountVectorizer. Adding Item_Value and Log_Item_Value (standardized) provided numerical context, addressing misclassifications (e.g., 5000060, 1001004) and boosting accuracy to 94%.\n",
    "> \n",
    "> \n",
    "> \n",
    "> Balanced Classes: The class_weight='balanced' setting in LogisticRegression improved performance on rare classes, reflected in the high macro F1 (0.91).\n",
    "> \n",
    "> \n",
    "> \n",
    "> Small Test Set: With only 51 test instances, reducing errors from 4 (92%) to 3 (94%) is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9737a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived features\n",
    "df_inv['Log_Taxes_Credit_Amount'] = np.log1p(df_inv['Taxes_Credit_Amount'])\n",
    "df_inv['Value_Category'] = pd.cut(df_inv['Item_Value'], bins=[0, 500, 2000, 5000, 10000, float('inf')], \n",
    "                                 labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "df_inv['Value_Category'] = df_inv['Value_Category'].cat.add_categories('Unknown').fillna('Unknown')\n",
    "# Purpose: Apply logarithmic transformation to Taxes_Credit_Amount to handle skewed distributions, \n",
    "# and create a categorical Value_Category feature based on Item_Value bins to capture value-based patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a21687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "df_inv_train = df_inv[df_inv[\"Dataset\"] == \"Training\"]\n",
    "df_inv_test = df_inv[df_inv[\"Dataset\"] == \"Test\"]\n",
    "\n",
    "# Define features and target\n",
    "X_train = df_inv_train[['Input_Text', 'Log_Item_Value', 'Item_Quantity', 'Taxes_Credit_%', 'Log_Taxes_Credit_Amount', 'Value_Category']]\n",
    "y_train = df_inv_train['Account_Number'].astype(str)  # Ensure string\n",
    "X_test = df_inv_test[['Input_Text', 'Log_Item_Value', 'Item_Quantity', 'Taxes_Credit_%', 'Log_Taxes_Credit_Amount', 'Value_Category']]\n",
    "y_test = df_inv_test['Account_Number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new pipeline that\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('text', CountVectorizer(ngram_range=(1, 2), max_features=3000, \n",
    "                             stop_words=['and', 'the', 'a', 'of', 'with', 'for', 'in', 'on', 'it', 'from', 'to'], \n",
    "                             ), 'Input_Text'),\n",
    "    ('value', StandardScaler(), ['Log_Item_Value']),\n",
    "    ('quantity', StandardScaler(), ['Item_Quantity']),\n",
    "    ('tax_rate', StandardScaler(), ['Taxes_Credit_%']),\n",
    "    ('tax_credit', StandardScaler(), ['Log_Taxes_Credit_Amount']),\n",
    "    ('category', CountVectorizer(max_features=10), 'Value_Category')\n",
    "])\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2544fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'preprocessing__text__max_features': [2000, 3000, 5000],\n",
    "    'clf__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=StratifiedKFold(n_splits=3), scoring='f1_macro')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best configuration:\", grid_search.best_params_)\n",
    "print(\"Best macro F1-score:\", grid_search.best_score_)\n",
    "pipeline = grid_search.best_estimator_\n",
    "# Purpose: Perform hyperparameter tuning using GridSearchCV with 3-fold stratified cross-validation, \n",
    "# optimizing the number of text features (max_features) and LogisticRegression regularization strength\n",
    "# (C) to maximize macro F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Acurácia no teste:\", pipeline.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=pipeline.classes_, yticklabels=pipeline.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Real Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a58b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong predicted classes \n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "erros_df = results_df[results_df['Actual'] != results_df['Predicted']]\n",
    "erros_df = erros_df.merge(df_inv_test[['Supplier_Name', 'Item_Description', 'Item_Value', 'Item_Quantity', 'Taxes_Credit_%']], left_index=True, right_index=True)\n",
    "print(\"Wrong predicted classes:\")\n",
    "print(erros_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de386d6",
   "metadata": {},
   "source": [
    "> The model correctly classified 98% of the 51 test instances (approximately 50 correct, 1 incorrect). This matches your project’s target accuracy of 98%, a significant improvement from the earlier 94% (3 errors) and 92% (text-only pipeline).\n",
    "> \n",
    "> \n",
    "> \n",
    "> > **Value_Category: **Binning Item_Value into categories (Very Low to Very High) captured ordinal patterns, improving classification for value-sensitive accounts like 1001004.\n",
    "> \n",
    "> > \n",
    "> \n",
    "> > \n",
    "> \n",
    "> > \n",
    "> \n",
    "> > **Hyperparameter Tuning: **GridSearchCV optimized max_features and C, fine-tuning the text feature space and regularization, which likely reduced the error rate to 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
